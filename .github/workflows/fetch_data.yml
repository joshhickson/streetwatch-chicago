# This GitHub Actions workflow automates the process of fetching new law enforcement
# sightings from Reddit, processing them, and updating the map data.

name: Fetch and Update Map Data

on:
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

  # Runs the workflow on a schedule. This is set to run every hour.
  schedule:
    - cron: '0 * * * *'

jobs:
  fetch-data:
    runs-on: ubuntu-latest

    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download spaCy base model
        # This is needed by the training script
        run: python -m spacy download en_core_web_sm

      - name: Build Custom NER Model
        # This step builds our custom model from the latest training data.
        # The model is built into the 'models/' directory, which is git-ignored.
        run: |
          export PYTHONPATH=.
          python src/train_ner.py

      - name: Run data fetching script
        # This step runs the Python script to fetch and process data using the
        # freshly built custom model.
        env:
          PYTHONPATH: .
          REDDIT_API_ID: ${{ secrets.REDDIT_API_ID }}
          REDDIT_API_SECRET: ${{ secrets.REDDIT_API_SECRET }}
          GOOGLE_GEOCODE_API_KEY: ${{ secrets.GOOGLE_GEOCODE_API_KEY }}
          REDDIT_USER_AGENT: "StreetWatchBot:v1.0 (by /u/YourUsername)"
        run: python src/scheduled_fetch.py

      - name: Upload Logs as Artifact
        # If the workflow runs, upload the log file for debugging purposes.
        uses: actions/upload-artifact@v3
        with:
          name: execution-logs
          path: logs/